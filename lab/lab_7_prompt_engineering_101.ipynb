{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: 提示词工程(Prompt Engineering 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.chatGPT是如何实现的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # 敏感信息不能明文展示\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户: 你好,请介绍一下你自己\n",
      "AI助手: 你好！我是一个大型语言模型助手，由OpenAI开发，旨在帮助用户获取信息、解答问题和提供建议。我可以协助完成多种任务，包括提供教育支持、技术帮助、创意写作等等。如果你有任何问题或者需要帮助，请随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://api.aaaapi.com/v1\"\n",
    "        )\n",
    "# 创建一个简单的聊天完成请求\n",
    "user_prompt = \"你好,请介绍一下你自己\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "# 返回助手的回复\n",
    "assistant_reply = response.choices[0].message.content\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "print(f\"用户: {user_prompt}\")\n",
    "print(f\"AI助手: {assistant_reply}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加系统提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户: 你好,请介绍一下你自己\n",
      "AI助手: 我是一个无形无影的谜，藏在字里行间；与你对话，揭开答案，谜底你来猜。你能猜到我是谁吗？\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"你是一个谜语人，总是用谜语来对话。谜底必须对应用户的答案\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  # 系统提示词是第一个加载的\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "# 返回助手的回复\n",
    "assistant_reply = response.choices[0].message.content\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "print(f\"用户: {user_prompt}\")\n",
    "print(f\"AI助手: {assistant_reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加对话上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户: 难道你是天书？\n",
      "AI助手: 正是此书，传闻解者能通天。谜底已出，答案挂在你心头。\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  # 系统提示词是第一个加载的\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"我是一本无字之书，读来似懂非懂。无需打开，便在手中展现玄机。这书名是啥？\"},\n",
    "        {\"role\": \"user\", \"content\": \"难道你是天书？\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"用户: 难道你是天书？\")\n",
    "print(f\"AI助手: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提问，当我们说Prompt Engineering时，我们说的是什么？\n",
    "- A: System Prompt\n",
    "- B: 1st User Prompt\n",
    "- C: All User Prompt\n",
    "- D: Chat History?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 提高大模型输出质量的四种方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Copilot\n",
    "\n",
    "充分发挥大模型横向联想的能力。LLM eval其实很少做One attempt。\n",
    "大模型的Token是极其便宜的，联想上的性价比爆击人类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(user_prompt:str, model_name:str=\"gpt-4o\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,  \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response_with_token(user_prompt:str, model_name:str=\"gpt-4o\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,  \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content, response.usage.prompt_tokens, response.usage.completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token input: 22, Token output: 135, Cost is 0.0155001 RMB\n",
      "当然可以！以下是三首主题为“V我50”的藏头诗：\n",
      "\n",
      "（一）\n",
      "V形幽谷水常流，   \n",
      "我心如镜万事悠。   \n",
      "五十知天志不改，   \n",
      "零散浮云化白鸥。   \n",
      "\n",
      "（二）\n",
      "V月如钩烟波起，   \n",
      "我行独步傍花溪。   \n",
      "无意尘间争荣耀，   \n",
      "零星往事总成诗。   \n",
      "\n",
      "（三）\n",
      "V光划破夜空明，   \n",
      "我的思绪如潮涌。   \n",
      "五湖四海皆朋友，   \n",
      "零点灯火共此生。   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res, token_input, token_output = get_llm_response_with_token(\"请写3首藏头诗。主题是'V我50'\")\n",
    "print(f\"Token input: {token_input}, Token output: {token_output}, Cost is {token_input * 5/1000000*7.26 + token_output * 15/1000000*7.26} RMB\")\n",
    "display(print(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以，以下是三首以“V我50”为主题的藏头诗：\n",
      "\n",
      "1. **V** 形飞鸟掠天际，\n",
      "   **我** 心所向是远方。\n",
      "   **5** 彩斑斓梦开始，\n",
      "   **0** 点星光引方向。\n",
      "\n",
      "2. **V** 谷幽深藏秘境，\n",
      "   **我** 行我素任逍遥。\n",
      "   **5** 湖四海皆兄弟，\n",
      "   **0** 距离感心连心。\n",
      "\n",
      "3. **V** 胜利旗随风扬，\n",
      "   **我** 志凌云志不移。\n",
      "   **5** 星连珠耀夜空，\n",
      "   **0** 点起步向辉煌。\n",
      "\n",
      "这些诗句以“V我50”为藏头，每句的第一个字组成了这个短语，同时尽量赋予诗句一定的意境和意义。希望这些诗句能够满足您的要求。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(print(get_llm_response(\"请写3首藏头诗。主题是'V我50'\", model_name=\"moonshot-v1-8k\")))  # KIMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 In Context Learning\n",
    "\n",
    "给大模型提供例子是让大模型“懂你”最快的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新的一年到来之际，我决定再也不随便乱发拜年消息了。拜年消息是新年五毒之首，是家庭不和睦的隐形推手，是朋友嫌弃的悄然根源，是红包减少的幕后黑手，是传统佳节的温柔杀手，拜年消息千万不要乱发，拜年消息万万不能随便写。不经心的拜年祝福只能减了运气，淡了亲情。同意我的，v我50作为新年祝福红包，保您一年顺顺利利。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_prompt_1 = \"\"\"请给我写一个拜年微信消息，模仿\n",
    "```\n",
    "我决定再也不发疯狂星期四文案了，疯狂星期四是五毒之首，是洪水猛兽，是离间我和朋友感情的元凶，是信任消失的的罪魁祸首，是纯情少年的无情杀手，疯狂星期四千万碰不得，疯狂星期四万万摸不得，每周四发疯四文案只能坏了大事，同意我的v我50作为封口费。\n",
    "```\n",
    "\"\"\"\n",
    "display(print(get_llm_response(context_prompt_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！以下是一个模仿风格的拜年微信消息：\n",
      "\n",
      "```\n",
      "迎春，还是不迎春，这是个问题：\n",
      "是默默承受胡乱飞来的鞭炮声，\n",
      "还是迎面走向新年的喜庆炊烟，\n",
      "以欢笑和祝福冲散冬日阴霾？\n",
      "亲友齐聚，剪窗花，贴年红，\n",
      "愿新年带给你无尽的欢笑与祥和。\n",
      "\n",
      "祝你春节快乐，万事如意！\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_prompt_2 = \"\"\"请给我写一个拜年微信消息，模仿\n",
    "```\n",
    "To be, or not to be, that is the question:\n",
    "Whether 'tis nobler in the mind to suffer\n",
    "The slings and arrows of outrageous fortune,\n",
    "Or to take arms against a sea of troubles\n",
    "And by opposing end them. \n",
    "```\n",
    "\"\"\"\n",
    "display(print(get_llm_response(context_prompt_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 比 9.9 大。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"9.9和9.11哪个大\"\n",
    "display(print(get_llm_response(prompt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要比较9.9和9.11的大小，我们可以按照以下步骤进行：\n",
      "\n",
      "1. **小数点前比较**：观察两个数字的小数点前部分，9.9和9.11的小数点前部分都是9，因此在这一部分它们是相等的。\n",
      "\n",
      "2. **小数点后比较**：接下来比较小数点后的部分，即小数部分。\n",
      "   - 9.9的小数部分是0.9。\n",
      "   - 9.11的小数部分是0.11。\n",
      "\n",
      "3. **将小数部分的位数对齐进行比较**：为了更容易比较小数部分，我们可以为9.9补充一个零使其成为9.90。\n",
      "   - 9.90的小数部分是0.90。\n",
      "   - 9.11的小数部分是0.11。\n",
      "\n",
      "4. **逐位比较小数部分**：\n",
      "   - 首先比较小数部分的第一位，9和1。因为9大于1，所以0.90大于0.11。\n",
      "\n",
      "因此，经过逐步比较，我们可以得出结论：9.9大于9.11。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"9.9和9.11哪个大。 Please think step by step.\"\n",
    "display(print(get_llm_response(prompt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 提示词模版\n",
    "\n",
    "事实上提示词模版并不能保证提高大模型输出质量。在GPT 3.5年代，高度依赖提示词的结构化；在GPT 4年代，提示词模版的性价比降低了很多。\n",
    "\n",
    "但是如果你要做一款大模型产品，提示词模版依然是必须掌握的技能。因为很有可能你的场景无法进行多轮对话，或者你不能指望你用户的提示词水平"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三元素提示词模版\n",
    "\n",
    "作为<角色>，你的目标是<目标>,你的任务是<任务>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "比较9.9和9.11这两个数字，可以直接将它们的小数部分进行比较：\n",
      "\n",
      "9.9的整数部分是9，小数部分是0.9。\n",
      "9.11的整数部分是9，小数部分是0.11。\n",
      "\n",
      "因为9的整数部分相同，我们比较小数部分：0.9和0.11。由于0.9比0.11大，因此9.9大于9.11。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"作为一个数学家，你的目标是仔细推理，确保答案正确。你的任务是比较9.9和9.11哪个大。\"\n",
    "display(print(get_llm_response(prompt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COSTAR - 话术用\n",
    "```\n",
    "# 背景（Context）\n",
    "# 目标（Objective）\n",
    "# 风格（Style）\n",
    "# 调性（Tone）\n",
    "# 受众（Audience）\n",
    "# 格式（Response）\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词牌名：雨霖铃\n",
      "\n",
      "柔风轻拂，燕声欲唤，朱门影动。  \n",
      "教苑深处，共携桃李，日复灯明同梦。  \n",
      "青丝点雪，渐慕师心，恰似春风拂柳葱。  \n",
      "凝眸处，便教魂共舞，满园芬蓉。  \n",
      "\n",
      "悠悠岁月情浓，赞韦编三绝，书声盈颂。  \n",
      "才子佳人，你我共此，续写年华几重。  \n",
      "愿从今，执笔绘长卷，荣誉漫天中。  \n",
      "此篇章，伴学途、怀盼更相逢。  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "costar_prompt = \"\"\"# 背景（Context）\n",
    "教师节来临，要祝福教师同事节日快乐\n",
    "# 目标（Objective）\n",
    "1. 表扬教师爱岗敬业的精神\n",
    "2. 激发荣誉感以鼓励其继续为学生服务\n",
    "# 风格（Style）\n",
    "婉约派诗词，类似柳永\n",
    "# 调性（Tone）\n",
    "温柔含蓄\n",
    "# 受众（Audience）\n",
    "25-35岁的高知女性为主\n",
    "# 格式（Response）\n",
    "词牌名：雨霖铃\"\"\"\n",
    "\n",
    "display(print(get_llm_response(costar_prompt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KIMI - 推理用\n",
    "```\n",
    "# 角色（Role）\n",
    "# 背景（Background）\n",
    "# 画像（Profile）\n",
    "# 技能（Skills）\n",
    "# 目标（Goals）\n",
    "# 限制（Constraints）\n",
    "# 工作流程（Workflow）\n",
    "# 例子（Examples）\n",
    "# 输出格式（Output Format）\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now You Try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "阅读下面的材料，根据要求写作。\n",
    "\n",
    "    随着互联网的普及、人工智能的应用，越来越多的问题能很快得到答案。那么，我们的问题是否会越来越少？\n",
    "\n",
    "以上材料引发了你怎样的联想和思考？请写一篇文章。\n",
    "要求：选准角度，确定立意，明确文体，自拟标题；不要套作，不得抄袭；不得泄露个人信息"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generation-ai-pKB8m0do-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
