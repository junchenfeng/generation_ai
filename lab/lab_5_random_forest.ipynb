{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: 集成模型(Ensemble Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('../data/loan_data.csv').head(2000)  # 为了避免后面计算性能降低太多\n",
    "X = data.drop('loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 数值和分类特征列表\n",
    "\n",
    "categorical_features = [\n",
    "    'person_gender', 'person_education', 'person_home_ownership',\n",
    "    'loan_intent', 'previous_loan_defaults_on_file'\n",
    "]\n",
    "\n",
    "transformers = [\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'person_age', 'person_income', 'person_emp_exp', 'loan_amnt',\n",
    "    'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n",
    "    'credit_score'\n",
    "]\n",
    "transformers.append(('num', StandardScaler(), numerical_features))\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 训练和使用RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 创建模型管道\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly_features', poly),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 训练模型\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 输出分类报告\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们看一棵树 【JC DEMO Only】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# 从pipeline中提取随机森林分类器\n",
    "rf_classifier = pipeline.named_steps['classifier']\n",
    "\n",
    "# 提取第一棵树\n",
    "estimator = rf_classifier.estimators_[0]\n",
    "\n",
    "# 获取特征名称\n",
    "feature_names = (\n",
    "    # 获取分类特征的名称\n",
    "    pipeline.named_steps['preprocessor']\n",
    "    .named_transformers_['cat']\n",
    "    .get_feature_names_out([\n",
    "        'person_gender', 'person_education', 'person_home_ownership',\n",
    "        'loan_intent', 'previous_loan_defaults_on_file'\n",
    "    ]).tolist() +\n",
    "    # 获取数值特征的名称\n",
    "    [\n",
    "        'person_age', 'person_income', 'person_emp_exp',\n",
    "        'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
    "        'cb_person_cred_hist_length', 'credit_score'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 获取多项式特征的名称\n",
    "poly_feature_names = pipeline.named_steps['poly_features'].get_feature_names_out(feature_names)\n",
    "\n",
    "# 导出树的结构为DOT格式\n",
    "dot_data = export_graphviz(estimator,\n",
    "                           out_file=None,\n",
    "                           feature_names=poly_feature_names,\n",
    "                           class_names=rf_classifier.classes_.astype(str),\n",
    "                           filled=True,\n",
    "                           rounded=True,\n",
    "                           special_characters=True,\n",
    "                           max_depth=3)  # 为了简化，可限制深度\n",
    "\n",
    "# 使用graphviz渲染\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")\n",
    "\n",
    "# 显示图像（在Jupyter Notebook中）\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Ensemble Model一个重要的好处是可以得到特征重要性。这使得特征工程可以更有针对性\n",
    "\n",
    "    - 思考你如何在perceptron classifier和SVM获取特征重要性信息？\n",
    "\n",
    "\n",
    "但是特征重要性的可解释性较弱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 获取特征名称\n",
    "# 获取所有特征名称\n",
    "feature_names = (\n",
    "    # 获取分类特征的名称\n",
    "    pipeline.named_steps['preprocessor']\n",
    "    .named_transformers_['cat']\n",
    "    .get_feature_names_out([\n",
    "        'person_gender', 'person_education', 'person_home_ownership',\n",
    "        'loan_intent', 'previous_loan_defaults_on_file'\n",
    "    ]).tolist() +\n",
    "    # 获取数值特征的名称\n",
    "    [\n",
    "        'person_age', 'person_income', 'person_emp_exp',\n",
    "        'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
    "        'cb_person_cred_hist_length', 'credit_score'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 获取多项式特征的名称\n",
    "feature_names = pipeline.named_steps['poly_features'].get_feature_names_out(feature_names)\n",
    "\n",
    "\n",
    "# 获取特征重要性\n",
    "importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# 创建特征重要性数据框\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# 按重要性排序\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 可视化特征重要性\n",
    "# 绘制所有特征重要性\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title('Feature Importances from Random Forest (All Features)')\n",
    "plt.xlim(0, 0.08)\n",
    "plt.show()\n",
    "\n",
    "# 绘制Top 10特征重要性\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances.head(10))\n",
    "plt.title('Feature Importances from Random Forest (Top 10 Features)')\n",
    "plt.xlim(0, 0.08)\n",
    "plt.show()\n",
    "\n",
    "# 打印前10-20名重要特征\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances.iloc[10:20])\n",
    "plt.title('Feature Importances from Random Forest (Features 10-20)')\n",
    "plt.xlim(0, 0.08)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ensemble Model调优\n",
    "## 2.1 参数调优\n",
    "群体参数：\n",
    "- n_estimators: 森林中树的数量。越多越好，但会增加计算量。\n",
    "- max_features: 每个树的特征选择方式。auto = sqrt(特征数量的平方根)。log2 = log2(特征数量)。特征越多，解释能力越强，单树越复杂，越容易过拟合。auto = sqrt。一般不调整这个\n",
    "\n",
    "单classifier参数：\n",
    "- max_depth: 每棵树的深度。深度越大，单树越复杂，越容易过拟合。\n",
    "- min_samples_split: 决定树的最小分裂样本数。值越小，单树越复杂，越容易过拟合。\n",
    "- min_samples_leaf：最终节点所需的最小样本数，值越小，单树越复杂，越容易过拟合。\n",
    "- max_leaf_nodes: 最终节点最大数量，值越大，单树越复杂，越容易过拟合。\n",
    "- criterion: 决定树的分类标准。gini = 基尼不纯度，entropy = 信息增益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200], # 森林级别参数，决定森林数量\n",
    "    'classifier__max_features': ['sqrt', 'log2'], # 森林级别参数。特征树决定单树的解释能力。\n",
    "    'classifier__max_depth': [None, 10, 20],  # 单决策树参数，决定树的深度。深度越大，单树越复杂，越容易过拟合。\n",
    "    'classifier__criterion': ['gini', 'entropy'] # 单决策树参数，决定树的分类标准。gini = 基尼不纯度，entropy = 信息增益。\n",
    "}\n",
    "\n",
    "# 创建带有GridSearch的管道\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=3, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=6)\n",
    "\n",
    "# 运行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 使用最佳模型进行预测\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 评估最佳模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy after GridSearchCV: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report after GridSearchCV:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**阅读上面的classifcation report， 你会做什么下一步的决策？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Now You Try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 尝试不同的Ensemble Model【JC DEMO ONLY】\n",
    "\n",
    "还有2个常见的ensemble model是GBDT和XGBoost。事实上在实际应用中，我常用的流程是特征工程+Logistic Classifer进行一轮特征初筛，XGBoost进行模型训练，并以AUC作为结果汇报。\n",
    "\n",
    "这里我们用RF给出的最重要的100个特征，尝试用XGBoost进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最重要的50个特征\n",
    "feature_importances = pd.DataFrame(\n",
    "    best_model.named_steps['classifier'].feature_importances_,\n",
    "    index=get_feature_names(best_model.named_steps['preprocessor'], \n",
    "                          best_model.named_steps['poly_features']),\n",
    "    columns=['importance']\n",
    ").sort_values('importance', ascending=False)\n",
    "\n",
    "# 获取前50个最重要特征的名称\n",
    "top_features = feature_importances.head(100).index.tolist()\n",
    "\n",
    "# 创建一个新的pipeline，只处理特征转换\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('preprocessor', best_model.named_steps['preprocessor']),\n",
    "    ('poly_features', best_model.named_steps['poly_features'])\n",
    "])\n",
    "\n",
    "# 使用preprocessing_pipeline转换数据\n",
    "X_train_transformed = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test_transformed = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "# 转换为DataFrame并选择top 50特征\n",
    "filtered_x_train = pd.DataFrame(\n",
    "    X_train_transformed,\n",
    "    columns=get_feature_names(best_model.named_steps['preprocessor'], \n",
    "                            best_model.named_steps['poly_features'])\n",
    ")[top_features]\n",
    "\n",
    "filtered_x_test = pd.DataFrame(\n",
    "    X_test_transformed,\n",
    "    columns=get_feature_names(best_model.named_steps['preprocessor'],\n",
    "                            best_model.named_steps['poly_features'])\n",
    ")[top_features]\n",
    "\n",
    "print(f\"筛选后的特征数量: {len(top_features)}\")\n",
    "print('\\n'.join(top_features))\n",
    "print(f\"筛选后训练集形状: {filtered_x_train.shape}\")\n",
    "print(f\"筛选后测试集形状: {filtered_x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier  # https://xgboost.readthedocs.io/en/stable/\n",
    "\n",
    "# 创建XGBoost模型\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# 使用GridSearchCV进行参数调优\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    xgb_model,\n",
    "    param_grid={\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 9], \n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=6\n",
    ")\n",
    "\n",
    "# 在筛选后的训练数据上训练模型\n",
    "xgb_grid_search.fit(filtered_x_train, y_train)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"XGBoost最佳参数:\", xgb_grid_search.best_params_)\n",
    "\n",
    "# 使用最佳模型在筛选后的测试数据上进行预测\n",
    "xgb_best_model = xgb_grid_search.best_estimator_\n",
    "xgb_y_pred = xgb_best_model.predict(filtered_x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "# 汇报F1 Score\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "print(f\"\\nXGBoost准确率: {xgb_accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nXGBoost分类报告:\")\n",
    "print(classification_report(y_test, xgb_y_pred))\n",
    "\n",
    "# 计算训练集和测试集的预测概率\n",
    "xgb_train_probs = xgb_best_model.predict_proba(filtered_x_train)[:, 1]\n",
    "xgb_test_probs = xgb_best_model.predict_proba(filtered_x_test)[:, 1]\n",
    "\n",
    "\n",
    "# 计算ROC曲线的假正率和真正率\n",
    "train_fpr, train_tpr, _ = roc_curve(y_train, xgb_train_probs)\n",
    "test_fpr, test_tpr, _ = roc_curve(y_test, xgb_test_probs)\n",
    "\n",
    "# 计算AUC值\n",
    "train_auc = roc_auc_score(y_train, xgb_train_probs)\n",
    "test_auc = roc_auc_score(y_test, xgb_test_probs)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(train_fpr, train_tpr, label=f'Train (AUC = {train_auc:.3f})', color='blue')\n",
    "plt.plot(test_fpr, test_tpr, label=f'Validation (AUC = {test_auc:.3f})', color='red')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # 绘制对角线\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('XGBoost ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generation-ai-pKB8m0do-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
