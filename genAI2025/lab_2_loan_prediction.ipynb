{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: 机器学习入门：贷款申请预测\n",
    "\n",
    "在这个项目中，我们将学习如何使用机器学习来预测银行是否会批准贷款申请。\n",
    "\n",
    "我们将学习以下内容：\n",
    "1. 数据探索和可视化（EDA）\n",
    "2. ML pipeline\n",
    "3. 如何评估模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 理论复习\n",
    "\n",
    "你准备考TOFEL，下面是你可以选择的一些备考方案（Policy）\n",
    "1. 去庙里求个签\n",
    "2. 买本书回家自己刷\n",
    "3. 报个新东方培训班\n",
    "4. 请个私教\n",
    "\n",
    "### 问题\n",
    "\n",
    "1. 在这个背景里，你的优化目标是什么？\n",
    "2. 你的训练损失是什么？你的泛化损失是什么？\n",
    "3. 在这个背景下，你的feature set是什么？\n",
    "4. 你通过背答案，在模拟考上得了很高分，但是在真实考试中却一塌胡涂。这种现象在机器学习里叫什么？\n",
    "5. 为什么有人会花钱去国外参加考机考？而不是在国内做笔试？\n",
    "6. 【挑战题】什么是VC维？(VC维刻画的是什么？)。为什么从1到4的VC维不断升高？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trick**设置中文字体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 设置中文字体\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['Heiti TC'] # 或者 'Arial Unicode MS', 'PingFang SC' 等\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "except Exception as e:\n",
    "    print(f\"设置中文字体失败: {e}。标签可能显示不正确。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 探索性数据分析（**E**xploratory **D**ata **A**nalysis）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Context \n",
    "\n",
    "### 2.1.1 元数据(Metadata)\n",
    "| Column | Description | Type |\n",
    "|--------|-------------|------|\n",
    "| person_age | Age of the person | Float |\n",
    "| person_gender | Gender of the person | Categorical |\n",
    "| person_education | Highest education level | Categorical |\n",
    "| person_income | Annual income | Float |\n",
    "| person_emp_exp | Years of employment experience | Integer |\n",
    "| person_home_ownership | Home ownership status (e.g., rent, own, mortgage) | Categorical |\n",
    "| loan_amnt | Loan amount requested | Float |\n",
    "| loan_intent | Purpose of the loan | Categorical |\n",
    "| loan_int_rate | Loan interest rate | Float |\n",
    "| cb_person_cred_hist_length | Length of credit history in years | Float |\n",
    "| credit_score | Credit score of the person | Integer |\n",
    "| previous_loan_defaults_on_file | Indicator of previous loan defaults | Categorical |\n",
    "| loan_status (target variable) | Loan approval status: 1 = approved; 0 = rejected | Integer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 提供技术环境信息\n",
    "\n",
    "- 请使用pandas， matplotlib， sklearn这三个python package（也可以在mdc文件中设置）\n",
    "\n",
    "- 项目目录结构\n",
    "```\n",
    "|\n",
    "|- data // 数据目录\n",
    "|   |-- loan_data.csv\n",
    "|- lab.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般import package都独立置顶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 数据探索分析（EDA）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请用这个提示词去生成EDA代码。 模式选择 **“Ask”**，模型调整为Gemini-2.5-pro，打开max模式，充分释放模型能力\n",
    "```\n",
    "请读取loan data数据，生成EDA方案帮我熟悉这个数据集，为预测做准备。请先不要生成代码\n",
    "```\n",
    "在chat中和gemini达成一致后，让它生成多个code block，以便于你在notebook中执行和判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置中文字体\n",
    "# 注意：请确保你的环境中有所需的字体，例如 'Heiti TC', 'Arial Unicode MS', 'PingFang SC', 'SimHei' 等\n",
    "# 如果以下某种字体不存在，请尝试替换为你的系统中可用的中文字体\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['Heiti TC'] # 优先使用 'Heiti TC'\n",
    "    # 或者尝试其他常用中文字体\n",
    "    # plt.rcParams['font.sans-serif'] = ['SimHei'] # 黑体\n",
    "    # plt.rcParams['font.sans-serif'] = ['PingFang SC'] # 苹方\n",
    "    # plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 正确显示负号\n",
    "except Exception as e:\n",
    "    print(f\"设置中文字体失败: {e}。标签可能显示不正确。\")\n",
    "    print(\"请尝试安装并使用系统中可用的中文字体，例如 'SimHei', 'PingFang SC', 'Microsoft YaHei' 等。\")\n",
    "\n",
    "# 加载数据\n",
    "try:\n",
    "    df = pd.read_csv('data/loan_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"错误：'data/loan_data.csv' 文件未找到。请确保文件路径正确。\")\n",
    "    # 在后续代码块执行前，你需要确保数据已正确加载，否则会报错。\n",
    "    # 你可能需要调整路径，例如 '../data/loan_data.csv' 或提供绝对路径。\n",
    "    df = pd.DataFrame() # 创建一个空的DataFrame以避免后续代码块立即报错，但请务必解决文件路径问题\n",
    "\n",
    "# 显示数据前5行\n",
    "print(\"数据前5行:\")\n",
    "if not df.empty:\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"数据未能加载，无法显示。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"\\n1. 数据基本信息概览\")\n",
    "    print(\"==========================\")\n",
    "\n",
    "    # 1.1 数据集的维度\n",
    "    print(\"\\n1.1 数据集的维度 (行数, 列数):\")\n",
    "    print(df.shape)\n",
    "\n",
    "    # 1.2 列名和数据类型\n",
    "    print(\"\\n1.2 列名和数据类型:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # 1.3 缺失值检查\n",
    "    print(\"\\n1.3 缺失值数量和百分比:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(df)) * 100\n",
    "    missing_data = pd.DataFrame({'缺失数量': missing_values, '缺失百分比(%)': missing_percentage})\n",
    "    missing_data = missing_data[missing_data['缺失数量'] > 0].sort_values(by='缺失百分比(%)', ascending=False)\n",
    "    if missing_data.empty:\n",
    "        print(\"数据集中没有缺失值。\")\n",
    "    else:\n",
    "        print(missing_data)\n",
    "\n",
    "    # 1.4 数值型特征的统计描述\n",
    "    print(\"\\n1.4 数值型特征的统计描述:\")\n",
    "    # 根据元数据，显式选择数值型列进行描述，避免潜在的非数值列错误\n",
    "    # 'person_age', 'person_income', 'person_emp_exp', 'loan_amnt', \n",
    "    # 'loan_int_rate', 'cb_person_cred_hist_length', 'credit_score'\n",
    "    # 目标变量 loan_status 虽然是整数，但其统计描述意义不大，主要看分布\n",
    "    numerical_cols = ['person_age', 'person_income', 'person_emp_exp', 'loan_amnt', \n",
    "                      'loan_int_rate', 'cb_person_cred_hist_length', 'credit_score']\n",
    "    # 确保这些列实际存在于DataFrame中，以防万一\n",
    "    existing_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "    if existing_numerical_cols:\n",
    "        print(df[existing_numerical_cols].describe())\n",
    "    else:\n",
    "        print(\"未能找到定义的数值型列。\")\n",
    "\n",
    "    # 1.5 分类型特征的取值类别和频率\n",
    "    print(\"\\n1.5 分类型特征的取值类别和频率:\")\n",
    "    # 根据元数据选择分类型列\n",
    "    # 'person_gender', 'person_education', 'person_home_ownership', \n",
    "    # 'loan_intent', 'previous_loan_defaults_on_file'\n",
    "    # 目标变量 'loan_status' 将在下一步单独分析\n",
    "    categorical_cols = ['person_gender', 'person_education', 'person_home_ownership', \n",
    "                        'loan_intent', 'previous_loan_defaults_on_file']\n",
    "    existing_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "    \n",
    "    if existing_categorical_cols:\n",
    "        for col in existing_categorical_cols:\n",
    "            print(f\"\\n特征: {col}\")\n",
    "            print(df[col].value_counts(dropna=False)) # dropna=False 以显示 NaN 的计数\n",
    "            print(\"-\" * 30)\n",
    "    else:\n",
    "        print(\"未能找到定义的分类型列。\")\n",
    "else:\n",
    "    print(\"数据未能加载，跳过数据基本信息概览。请先确保数据已成功加载。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and 'loan_status' in df.columns:\n",
    "    print(\"\\n2. 目标变量分析 (`loan_status`)\")\n",
    "    print(\"===================================\")\n",
    "\n",
    "    # 2.1 目标变量的类别数量和百分比\n",
    "    print(\"\\n2.1 目标变量的类别数量:\")\n",
    "    status_counts = df['loan_status'].value_counts(dropna=False) # dropna=False 以防目标变量有缺失\n",
    "    print(status_counts)\n",
    "\n",
    "    print(\"\\n2.2 目标变量的类别百分比:\")\n",
    "    status_percentage = df['loan_status'].value_counts(normalize=True, dropna=False) * 100\n",
    "    print(status_percentage)\n",
    "\n",
    "    # 2.3 可视化目标变量的分布\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='loan_status', data=df, palette=['skyblue', 'salmon'])\n",
    "    plt.title('目标变量 loan_status 分布 (0: 拒绝, 1: 批准)')\n",
    "    plt.xlabel('贷款状态')\n",
    "    plt.ylabel('数量')\n",
    "    # 在条形图上显示具体数值\n",
    "    for i, count in enumerate(status_counts):\n",
    "        plt.text(i, count + 50, str(count), ha='center', va='bottom') #  count + 50 是为了让文本在条形图上方一点\n",
    "    plt.xticks([0, 1], ['拒绝 (0)', '批准 (1)']) # 设置x轴刻度标签\n",
    "    plt.show()\n",
    "\n",
    "    # 检查是否存在类别不平衡\n",
    "    if not status_counts.empty:\n",
    "        ratio = status_counts.min() / status_counts.max()\n",
    "        print(f\"\\n少数类别与多数类别的比例: {ratio:.2f}\")\n",
    "        if ratio < 0.1: # 一个常用的判断严重不平衡的阈值\n",
    "            print(\"警告：目标变量存在严重的类别不平衡！\")\n",
    "        elif ratio < 0.3:\n",
    "            print(\"提示：目标变量存在一定程度的类别不平衡。\")\n",
    "        else:\n",
    "            print(\"目标变量类别分布相对均衡。\")\n",
    "    \n",
    "    # 检查目标变量是否有缺失值\n",
    "    if df['loan_status'].isnull().sum() > 0:\n",
    "        print(f\"\\n警告：目标变量 'loan_status' 中存在 {df['loan_status'].isnull().sum()} 个缺失值！后续处理需要注意。\")\n",
    "\n",
    "else:\n",
    "    if df.empty:\n",
    "        print(\"数据未能加载，跳过目标变量分析。\")\n",
    "    else:\n",
    "        print(\"错误：数据集中未找到目标变量 'loan_status'，跳过目标变量分析。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    print(\"\\n3. 单变量分析 (Univariate Analysis)\")\n",
    "    print(\"======================================\")\n",
    "    print(\"\\n3.1 数值型特征分析\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    numerical_cols = ['person_age', 'person_income', 'person_emp_exp', 'loan_amnt', \n",
    "                      'loan_int_rate', 'cb_person_cred_hist_length', 'credit_score']\n",
    "    # 过滤掉数据中不存在的列，以防出错\n",
    "    existing_numerical_cols = [col for col in numerical_cols if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "    if not existing_numerical_cols:\n",
    "        print(\"在数据中未找到可分析的数值型特征或这些列不是数值类型。\")\n",
    "    else:\n",
    "        for col in existing_numerical_cols:\n",
    "            if df[col].isnull().all(): # 如果列中所有值都缺失，则跳过绘图\n",
    "                print(f\"\\n特征 '{col}' 所有值均缺失，跳过可视化。\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n分析特征: {col}\")\n",
    "            \n",
    "            # 检查是否有足够的多样性来绘图，避免只有一个唯一值（除NaN外）导致绘图错误\n",
    "            if df[col].nunique(dropna=True) < 2 :\n",
    "                 print(f\"特征 '{col}' 的非缺失唯一值少于2个，可能不适合绘制直方图/箱线图。\")\n",
    "                 print(df[col].value_counts(dropna=False)) # 显示其值计数\n",
    "                 # 可以选择在这里跳过绘图，或者让它尝试绘制（可能会产生不太有信息的图）\n",
    "                 # continue\n",
    "\n",
    "            plt.figure(figsize=(12, 4))\n",
    "\n",
    "            # 绘制直方图和核密度估计 (KDE)\n",
    "            plt.subplot(1, 2, 1)\n",
    "            sns.histplot(df[col], kde=True, bins=30) # kde=True 会添加核密度估计曲线\n",
    "            plt.title(f'{col} - 直方图与KDE')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('频率')\n",
    "\n",
    "            # 绘制箱线图\n",
    "            plt.subplot(1, 2, 2)\n",
    "            sns.boxplot(y=df[col])\n",
    "            plt.title(f'{col} - 箱线图')\n",
    "            plt.ylabel(col)\n",
    "\n",
    "            plt.tight_layout() # 调整子图布局，防止重叠\n",
    "            plt.show()\n",
    "            \n",
    "            # 打印一些统计信息，辅助判断\n",
    "            print(f\"特征 '{col}' 的偏度 (Skewness): {df[col].skew():.2f}\")\n",
    "            print(f\"特征 '{col}' 的峰度 (Kurtosis): {df[col].kurt():.2f}\")\n",
    "            # 简单识别潜在异常值（基于IQR，这是一种常见但不绝对的方法）\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "            if not outliers.empty:\n",
    "                print(f\"特征 '{col}' 中基于IQR方法识别的潜在异常值数量: {len(outliers)}\")\n",
    "                # print(f\"潜在异常值示例 (最多5个): {outliers.head().tolist()}\")\n",
    "            else:\n",
    "                print(f\"特征 '{col}' 中未基于IQR方法识别到明显异常值。\")\n",
    "else:\n",
    "    print(\"数据未能加载，跳过单变量数值特征分析。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE*: \n",
    "1. 目前cursor对于jupyter notebook插入支持不好，经常翻车，所以选择ask模式更加实际。 此外，数据分析主要是探索和思考，有大量人机合作，所以agent模式的自动执行助力也不大\n",
    "\n",
    "2. 一般package import和环境变量设置会放在最上层单独一个code cell；但是这里未来让大家看清楚各个包在哪里使用，所以拆开了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**挑战题** 你发现了什么有意思的模式么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据预处理\n",
    "\n",
    "任务1: 将分类变量进行One-Hot编码，分类变量包括性别, 教育水平, 购房情况, 贷款意图, 是否曾经违约\n",
    "\n",
    "任务2: 按照7:3分离训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 'df' 是在前面EDA步骤中加载并使用的DataFrame\n",
    "if 'df' in globals() and not df.empty:\n",
    "    print(\"\\n数据预处理开始...\")\n",
    "    print(\"任务1: 分类变量 One-Hot 编码\")\n",
    "    print(\"===================================\")\n",
    "\n",
    "    # 1. 创建一个副本以避免修改原始EDA用的DataFrame\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # 2. 定义需要进行One-Hot编码的分类变量列名\n",
    "    categorical_cols_to_encode = [\n",
    "        'person_gender', \n",
    "        'person_education', \n",
    "        'person_home_ownership', \n",
    "        'loan_intent', \n",
    "        'previous_loan_defaults_on_file'\n",
    "    ]\n",
    "\n",
    "    # 检查这些列是否实际存在于DataFrame中，避免因列名错误或数据加载不完整导致的问题\n",
    "    actual_cols_to_encode = [col for col in categorical_cols_to_encode if col in df_processed.columns]\n",
    "    \n",
    "    missing_cols = set(categorical_cols_to_encode) - set(actual_cols_to_encode)\n",
    "    if missing_cols:\n",
    "        print(f\"警告：以下指定的分类列在DataFrame中不存在，将不会被编码: {list(missing_cols)}\")\n",
    "\n",
    "    if not actual_cols_to_encode:\n",
    "        print(\"错误：没有在DataFrame中找到可用于One-Hot编码的指定分类列。请检查列名和数据加载过程。\")\n",
    "        # df_processed 保持原样，后续任务可能失败\n",
    "    else:\n",
    "        print(f\"将对以下列进行One-Hot编码: {actual_cols_to_encode}\")\n",
    "        # 3. 执行One-Hot编码\n",
    "        # pd.get_dummies 会自动处理NaN值（默认情况下，NaN值的那一行在所有新生成的虚拟列中都会是0）\n",
    "        # prefix 参数可以帮助我们识别这些新列的来源\n",
    "        df_processed = pd.get_dummies(df_processed, \n",
    "                                     columns=actual_cols_to_encode, \n",
    "                                     prefix=actual_cols_to_encode, \n",
    "                                     dummy_na=False) # dummy_na=False 是默认行为，不为NaN创建额外列\n",
    "        \n",
    "        # 4. 显示处理后的信息\n",
    "        print(\"\\nOne-Hot编码完成。\")\n",
    "        print(\"处理后DataFrame的形状 (行数, 列数):\")\n",
    "        print(df_processed.shape)\n",
    "        print(\"\\n处理后DataFrame的前5行:\")\n",
    "        print(df_processed.head())\n",
    "else:\n",
    "    print(\"错误: DataFrame 'df' 未定义或为空。请确保已成功执行前面的数据加载和EDA步骤。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务2: 按照7:3分离训练集和测试集\n",
    "# 假设 df_processed 是上一步One-Hot编码后的DataFrame\n",
    "if 'df_processed' in globals() and not df_processed.empty:\n",
    "    if 'loan_status' not in df_processed.columns:\n",
    "        print(\"错误: 目标变量 'loan_status' 不在处理后的DataFrame中。无法进行训练/测试集划分。\")\n",
    "    else:\n",
    "        print(\"\\n任务2: 训练集和测试集分离\")\n",
    "        print(\"===================================\")\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        import numpy as np # 用于检查非数值类型\n",
    "\n",
    "        # 1. 处理目标变量中的缺失值\n",
    "        initial_rows = len(df_processed)\n",
    "        df_processed.dropna(subset=['loan_status'], inplace=True) # 删除目标变量缺失的行\n",
    "        rows_after_dropna = len(df_processed)\n",
    "        \n",
    "        if rows_after_dropna < initial_rows:\n",
    "            print(f\"注意：从数据中删除了 {initial_rows - rows_after_dropna} 行，因为目标变量 'loan_status' 存在缺失值。\")\n",
    "\n",
    "        if df_processed.empty:\n",
    "            print(\"错误：在移除 'loan_status' 的缺失值后，DataFrame 为空。无法进行训练/测试集划分。\")\n",
    "        else:\n",
    "            # 2. 定义特征 (X) 和目标 (y)\n",
    "            y = df_processed['loan_status'].astype(int) # 确保目标变量是整数类型\n",
    "            X = df_processed.drop('loan_status', axis=1)\n",
    "\n",
    "            # 检查X中是否还存在非数值类型列（One-Hot编码后理论上不应有未处理的object类型）\n",
    "            non_numeric_cols_in_X = X.select_dtypes(exclude=np.number).columns\n",
    "            if not non_numeric_cols_in_X.empty:\n",
    "                print(f\"警告: 特征集 X 中仍包含以下非数值类型的列: {non_numeric_cols_in_X.tolist()}\")\n",
    "                print(\"这些列可能需要进一步检查和处理。模型训练通常需要所有特征都是数值型。\")\n",
    "                print(\"X中各列的数据类型:\")\n",
    "                print(X.dtypes)\n",
    "            \n",
    "            # 3. 执行训练集和测试集的分离\n",
    "            # stratify=y 确保类别比例在训练集和测试集中保持一致\n",
    "            # 添加 y.nunique() > 1 条件以避免在y只有一个类别时 stratify 出错\n",
    "            stratify_option = y if y.nunique() > 1 else None\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, \n",
    "                test_size=0.3, \n",
    "                random_state=42, \n",
    "                stratify=stratify_option\n",
    "            )\n",
    "\n",
    "            # 4. 显示结果\n",
    "            print(\"\\n训练集和测试集分离完成。\")\n",
    "            print(\"X_train 形状:\", X_train.shape)\n",
    "            print(\"X_test 形状:\", X_test.shape)\n",
    "            print(\"y_train 形状:\", y_train.shape)\n",
    "            print(\"y_test 形状:\", y_test.shape)\n",
    "\n",
    "            if stratify_option is not None:\n",
    "                print(\"\\ny_train 中目标变量的分布 (百分比):\")\n",
    "                print(y_train.value_counts(normalize=True) * 100)\n",
    "                print(\"\\ny_test 中目标变量的分布 (百分比):\")\n",
    "                print(y_test.value_counts(normalize=True) * 100)\n",
    "            else:\n",
    "                print(\"\\n目标变量只有一个类别，未进行分层抽样。\")\n",
    "                print(\"\\ny_train 中目标变量的分布:\")\n",
    "                print(y_train.value_counts())\n",
    "                print(\"\\ny_test 中目标变量的分布:\")\n",
    "                print(y_test.value_counts())\n",
    "\n",
    "            # 你现在可以将这些数据集用于模型训练：\n",
    "            # X_train, X_test, y_train, y_test\n",
    "            # (这些变量将存在于您的Notebook的全局作用域中)\n",
    "\n",
    "elif 'df_processed' not in globals() or df_processed.empty:\n",
    "    print(\"错误: DataFrame 'df_processed' 未定义或为空。请先成功执行One-Hot编码任务。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型训练\n",
    "\n",
    "### 4.1 基础训练\n",
    "#### 4.1.1 代码\n",
    "\n",
    "\n",
    "在训练集上训练一个决策树模型，给出F1-score和AUC两个评价指标，并画出ROC曲线\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1.1 对离散型(categorical)变量做`get_dummies()`处理\n",
    "categorical_cols = ['person_gender', 'person_education', 'person_home_ownership', \n",
    "                        'loan_intent', 'previous_loan_defaults_on_file']\n",
    "\n",
    "# 确保df已经加载并且不为空\n",
    "if 'df' in locals() and not df.empty:\n",
    "    df_dummies = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    print(\"经过get_dummies处理后的数据前5行:\")\n",
    "    print(df_dummies.head())\n",
    "    print(\"\\n处理后的数据维度:\")\n",
    "    print(df_dummies.shape)\n",
    "    # 更新原始DataFrame\n",
    "    # df = df_dummies \n",
    "    # 这一步通常在确认无误后再执行，或者创建一个新的DataFrame进行后续操作\n",
    "else:\n",
    "    print(\"数据未能加载，或者 'df' 未定义，跳过get_dummies处理。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd # 确保pandas已导入\n",
    "\n",
    "# 假设 df_dummies 是在4.1.1第一部分 get_dummies 处理后的 DataFrame\n",
    "# 如果你之前覆盖了原始的 df, 请使用 df 替换下面的 df_dummies\n",
    "\n",
    "if 'df_dummies' in locals() and not df_dummies.empty:\n",
    "    # 1. 定义特征 (X) 和目标 (y)\n",
    "    # 确保目标变量 'loan_status' 仍然在 df_dummies 中，并且没有被错误地编码\n",
    "    if 'loan_status' not in df_dummies.columns:\n",
    "        print(\"错误: 目标变量 'loan_status' 不在处理后的DataFrame中。\")\n",
    "        # 你可能需要从原始的 df 中获取 y，或者确保 get_dummies 没有移除它\n",
    "        # 例如: y = df['loan_status'].astype(int)\n",
    "        # X = df_dummies.drop('loan_status', axis=1, errors='ignore') # errors='ignore' 避免列不存在时报错\n",
    "    else:\n",
    "        y = df_dummies['loan_status'].astype(int)\n",
    "        X = df_dummies.drop('loan_status', axis=1)\n",
    "\n",
    "    # 确保X中的所有列都是数值类型 (get_dummies 应该已经处理了bool类型)\n",
    "    # 如果在get_dummies时使用了drop_first=True，那么bool类型会被转换为0和1的整数\n",
    "    # 如果没有，bool类型可能会保留，部分sklearn模型能处理，但显式转换更安全\n",
    "    X = X.astype(float) # 或者具体处理非数值列\n",
    "\n",
    "    # 2. 执行训练集和测试集的分离 (如果上一步任务2没有执行或者变量作用域问题，这里重新执行)\n",
    "    # stratify=y 确保类别比例在训练集和测试集中保持一致\n",
    "    stratify_option = y if y.nunique() > 1 else None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=stratify_option\n",
    "    )\n",
    "\n",
    "    print(\"训练集和测试集维度:\")\n",
    "    print(\"X_train 形状:\", X_train.shape)\n",
    "    print(\"X_test 形状:\", X_test.shape)\n",
    "    print(\"y_train 形状:\", y_train.shape)\n",
    "    print(\"y_test 形状:\", y_test.shape)\n",
    "\n",
    "    # 3. 初始化并训练决策树模型\n",
    "    # 你可以调整模型的参数，例如 max_depth, min_samples_split 等\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "    print(\"\\n决策树模型训练完成。\")\n",
    "\n",
    "    # 4. 在训练集上进行预测和评估\n",
    "    y_train_pred = dt_classifier.predict(X_train)\n",
    "    y_train_pred_proba = dt_classifier.predict_proba(X_train)[:, 1] # 获取正类的概率\n",
    "\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    auc_train = roc_auc_score(y_train, y_train_pred_proba)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "\n",
    "    print(\"\\n--- 训练集评估 ---\")\n",
    "    print(f\"F1-score (训练集): {f1_train:.4f}\")\n",
    "    print(f\"AUC (训练集): {auc_train:.4f}\")\n",
    "\n",
    "    # 5. 在测试集上进行预测和评估\n",
    "    y_test_pred = dt_classifier.predict(X_test)\n",
    "    y_test_pred_proba = dt_classifier.predict_proba(X_test)[:, 1] # 获取正类的概率\n",
    "\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred_proba)\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_proba)\n",
    "\n",
    "    print(\"\\n--- 测试集评估 ---\")\n",
    "    print(f\"F1-score (测试集): {f1_test:.4f}\")\n",
    "    print(f\"AUC (测试集): {auc_test:.4f}\")\n",
    "\n",
    "    # 6. 绘制ROC曲线\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fpr_train, tpr_train, label=f'训练集 ROC曲线 (AUC = {auc_train:.2f})')\n",
    "    plt.plot(fpr_test, tpr_test, label=f'测试集 ROC曲线 (AUC = {auc_test:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # 随机猜测线\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('假正例率 (False Positive Rate)')\n",
    "    plt.ylabel('真正例率 (True Positive Rate)')\n",
    "    plt.title('ROC 曲线')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "elif 'X_train' in locals() and 'X_test' in locals() and 'y_train' in locals() and 'y_test' in locals():\n",
    "    print(\"使用在任务2中已经分割好的 X_train, X_test, y_train, y_test。\")\n",
    "    \n",
    "    # 确保X_train, X_test中的所有列都是数值类型\n",
    "    X_train = X_train.astype(float)\n",
    "    X_test = X_test.astype(float)\n",
    "\n",
    "    # 3. 初始化并训练决策树模型\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "    print(\"\\n决策树模型训练完成。\")\n",
    "\n",
    "    # 4. 在训练集上进行预测和评估\n",
    "    y_train_pred = dt_classifier.predict(X_train)\n",
    "    y_train_pred_proba = dt_classifier.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    auc_train = roc_auc_score(y_train, y_train_pred_proba)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred_proba)\n",
    "\n",
    "    print(\"\\n--- 训练集评估 ---\")\n",
    "    print(f\"F1-score (训练集): {f1_train:.4f}\")\n",
    "    print(f\"AUC (训练集): {auc_train:.4f}\")\n",
    "\n",
    "    # 5. 在测试集上进行预测和评估\n",
    "    y_test_pred = dt_classifier.predict(X_test)\n",
    "    y_test_pred_proba = dt_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred_proba)\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred_proba)\n",
    "\n",
    "    print(\"\\n--- 测试集评估 ---\")\n",
    "    print(f\"F1-score (测试集): {f1_test:.4f}\")\n",
    "    print(f\"AUC (测试集): {auc_test:.4f}\")\n",
    "\n",
    "    # 6. 绘制ROC曲线\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fpr_train, tpr_train, label=f'训练集 ROC曲线 (AUC = {auc_train:.2f})')\n",
    "    plt.plot(fpr_test, tpr_test, label=f'测试集 ROC曲线 (AUC = {auc_test:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('假正例率 (False Positive Rate)')\n",
    "    plt.ylabel('真正例率 (True Positive Rate)')\n",
    "    plt.title('ROC 曲线')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"错误: 需要的 DataFrame ('df_dummies' 或 'X_train' 等) 未定义或为空。请确保已成功执行前面的数据处理和划分步骤。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集上给出F1-score和AUC两个评价指标，并画出ROC曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 讨论\n",
    "\n",
    "根据这个数据，你会做什么决策？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Cross Validation & Parameter Tuning\n",
    "\n",
    "#### 4.2.1 训练过程\n",
    "\n",
    "使用5 fold cross validation来做decision tree classifer的优化。\n",
    "\n",
    "请对于criterion，max_depth，min_samples_split和min_samples_leaf这四个parameter的grid search，评分方法是roc_auc。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 讨论\n",
    "\n",
    "根据这个数据，你会做什么决策？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 总结\n",
    "\n",
    "1. 学习了机器学习的基本过程：EDA -> 数据预处理 -> Parameter Choice\n",
    "2. 学习了如何使用F1-score & AUC来评估模型表现，并进行训练决策\n",
    "3. 学习了如何利用Gemini来进行辅助和代码执行\n",
    "\n",
    "机器学习是一个技术（technique）和手感（craftmanship）相结合的过程。成熟的工具包和LLM极大降低了technique达到合格水平的难度，因此模型表现更多来自手感。\n",
    "\n",
    "下一个lab，我们会讨论如何code 手感，kind of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回家作业\n",
    "\n",
    "对kaggle数据集中的train.csv进行EDA，以及利用决策树的预测，并在test上评估你的模型。我预期你在test上的AUC在0.7-0.75之间"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai2025-EbBYtNEX-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
